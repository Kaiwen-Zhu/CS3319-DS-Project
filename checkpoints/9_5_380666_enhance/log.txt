Arguments:
  data_root: /dssg/home/acct-stu/stu177/DS-project/data
  save_root: /dssg/home/acct-stu/stu177/DS-project/checkpoints
  init_author_path: author_init.bin
  batch_size: 16384
  epochs: 100
  train_frac: 0.9
  dims: [256, 128, 64, 32]
  enhance: True
  from_dir: 9
  enhance_frac: 5.0
  load_pair: True
#authors: 6611, #papers: 79937
#(author, paper) edge in train set: 614179, in test set: 136484
#(paper, paper) edge in train set: 294402, in test set: 65422
#(author, author) edge in train set: 8697, in test set: 1932
#authors in train set: 6610
#papers in train set: 79660
#desired predicted author-author edges: 43485
#desired predicted author-paper edges: 2098245
#desired predicted paper-paper edges: 1446050
#predicted author-author edges: 32392, min similarity is 0.9000
#predicted author-paper edges: 2098245, min similarity is 0.5667
#predicted paper-paper edges: 322610, min similarity is 0.9000
Graph(num_nodes={'author': 6611, 'paper': 79937},
      num_edges={('author', 'aa_pred', 'author'): 32392, ('author', 'ap_pred', 'paper'): 2098245, ('author', 'coauthor', 'author'): 24005, ('author', 'ref', 'paper'): 614179, ('paper', 'beref', 'author'): 614179, ('paper', 'cite', 'paper'): 668741, ('paper', 'pp_pred', 'paper'): 322610},
      metagraph=[('author', 'author', 'aa_pred'), ('author', 'author', 'coauthor'), ('author', 'paper', 'ap_pred'), ('author', 'paper', 'ref'), ('paper', 'author', 'beref'), ('paper', 'paper', 'cite'), ('paper', 'paper', 'pp_pred')])
Epoch 0: loss = 0.2465
Epoch 1: loss = 0.1170
Epoch 2: loss = 0.0968
Epoch 3: loss = 0.0856
Epoch 4: loss = 0.0780
Epoch 5: loss = 0.0722
Epoch 6: loss = 0.0680
Epoch 7: loss = 0.0645
Epoch 8: loss = 0.0622
Epoch 9: loss = 0.0595
Epoch 10: loss = 0.0574
Epoch 11: loss = 0.0560
Epoch 12: loss = 0.0542
Epoch 13: loss = 0.0528
Epoch 14: loss = 0.0520
Epoch 15: loss = 0.0505
Epoch 16: loss = 0.0498
Epoch 17: loss = 0.0489
Epoch 18: loss = 0.0480
Epoch 19: loss = 0.0471
Epoch 20: loss = 0.0463
Epoch 21: loss = 0.0458
Epoch 22: loss = 0.0450
Epoch 23: loss = 0.0445
Epoch 24: loss = 0.0438
Epoch 25: loss = 0.0427
Epoch 26: loss = 0.0430
Epoch 27: loss = 0.0424
Epoch 28: loss = 0.0418
Epoch 29: loss = 0.0413
Epoch 30: loss = 0.0406
Epoch 31: loss = 0.0405
Epoch 32: loss = 0.0400
Epoch 33: loss = 0.0399
Epoch 34: loss = 0.0390
Epoch 35: loss = 0.0389
Epoch 36: loss = 0.0384
Epoch 37: loss = 0.0381
Epoch 38: loss = 0.0380
Epoch 39: loss = 0.0376
Epoch 40: loss = 0.0374
Epoch 41: loss = 0.0371
Epoch 42: loss = 0.0368
Epoch 43: loss = 0.0364
Epoch 44: loss = 0.0360
Epoch 45: loss = 0.0361
Epoch 46: loss = 0.0359
Epoch 47: loss = 0.0357
Epoch 48: loss = 0.0354
Epoch 49: loss = 0.0353
Epoch 50: loss = 0.0348
Epoch 51: loss = 0.0350
Epoch 52: loss = 0.0343
Epoch 53: loss = 0.0345
Epoch 54: loss = 0.0345
Epoch 55: loss = 0.0336
Epoch 56: loss = 0.0338
Epoch 57: loss = 0.0338
Epoch 58: loss = 0.0340
Epoch 59: loss = 0.0333
Epoch 60: loss = 0.0336
Epoch 61: loss = 0.0334
Epoch 62: loss = 0.0333
Epoch 63: loss = 0.0327
Epoch 64: loss = 0.0325
Epoch 65: loss = 0.0325
Epoch 66: loss = 0.0323
Epoch 67: loss = 0.0321
Epoch 68: loss = 0.0322
Epoch 69: loss = 0.0321
Epoch 70: loss = 0.0319
Epoch 71: loss = 0.0320
Epoch 72: loss = 0.0317
Epoch 73: loss = 0.0318
Epoch 74: loss = 0.0315
Epoch 75: loss = 0.0314
Epoch 76: loss = 0.0315
Epoch 77: loss = 0.0316
Epoch 78: loss = 0.0311
Epoch 79: loss = 0.0310
Epoch 80: loss = 0.0310
Epoch 81: loss = 0.0309
Epoch 82: loss = 0.0309
Epoch 83: loss = 0.0308
Epoch 84: loss = 0.0305
Epoch 85: loss = 0.0303
Epoch 86: loss = 0.0303
Epoch 87: loss = 0.0304
Epoch 88: loss = 0.0302
Epoch 89: loss = 0.0301
Epoch 90: loss = 0.0300
Epoch 91: loss = 0.0301
Epoch 92: loss = 0.0300
Epoch 93: loss = 0.0298
Epoch 94: loss = 0.0298
Epoch 95: loss = 0.0296
Epoch 96: loss = 0.0294
Epoch 97: loss = 0.0296
Epoch 98: loss = 0.0296
Epoch 99: loss = 0.0293
Max f1 score of predicting reference edges: 0.9408 (precision = 0.9542, recall = 0.9278), threshold = -0.0739
Max f1 score of predicting citation edges: 0.8545 (precision = 0.8568, recall = 0.8523)
Max f1 score of predicting coauthor edges: 0.9820 (precision = 0.9755, recall = 0.9886)
