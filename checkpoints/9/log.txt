Arguments:
  data_root: /dssg/home/acct-stu/stu177/DS-project/data
  save_root: /dssg/home/acct-stu/stu177/DS-project/checkpoints
  init_author_path: author_init.bin
  batch_size: 16384
  epochs: 100
  train_frac: 0.9
  dims: [256, 128, 64, 32]
  enhance: False
  from_dir: /dssg/home/acct-stu/stu177/DS-project/checkpoints/9_237442
  enhance_frac: 1
#authors: 6611, #papers: 79937
#(author, paper) edge in train set: 614179, in test set: 136484
#(paper, paper) edge in train set: 294402, in test set: 65422
#(author, author) edge in train set: 8697, in test set: 1932
#authors in train set: 6610
#papers in train set: 79660
Graph(num_nodes={'author': 6611, 'paper': 79937},
      num_edges={('author', 'coauthor', 'author'): 24005, ('author', 'ref', 'paper'): 614179, ('paper', 'beref', 'author'): 614179, ('paper', 'cite', 'paper'): 668741},
      metagraph=[('author', 'author', 'coauthor'), ('author', 'paper', 'ref'), ('paper', 'author', 'beref'), ('paper', 'paper', 'cite')])
Epoch 0: loss = 0.3260
Epoch 1: loss = 0.1439
Epoch 2: loss = 0.1218
Epoch 3: loss = 0.1092
Epoch 4: loss = 0.1006
Epoch 5: loss = 0.0942
Epoch 6: loss = 0.0893
Epoch 7: loss = 0.0851
Epoch 8: loss = 0.0821
Epoch 9: loss = 0.0789
Epoch 10: loss = 0.0773
Epoch 11: loss = 0.0746
Epoch 12: loss = 0.0726
Epoch 13: loss = 0.0711
Epoch 14: loss = 0.0697
Epoch 15: loss = 0.0681
Epoch 16: loss = 0.0673
Epoch 17: loss = 0.0658
Epoch 18: loss = 0.0651
Epoch 19: loss = 0.0640
Epoch 20: loss = 0.0628
Epoch 21: loss = 0.0620
Epoch 22: loss = 0.0615
Epoch 23: loss = 0.0607
Epoch 24: loss = 0.0603
Epoch 25: loss = 0.0590
Epoch 26: loss = 0.0590
Epoch 27: loss = 0.0584
Epoch 28: loss = 0.0579
Epoch 29: loss = 0.0569
Epoch 30: loss = 0.0563
Epoch 31: loss = 0.0560
Epoch 32: loss = 0.0555
Epoch 33: loss = 0.0553
Epoch 34: loss = 0.0548
Epoch 35: loss = 0.0545
Epoch 36: loss = 0.0541
Epoch 37: loss = 0.0535
Epoch 38: loss = 0.0527
Epoch 39: loss = 0.0531
Epoch 40: loss = 0.0524
Epoch 41: loss = 0.0523
Epoch 42: loss = 0.0523
Epoch 43: loss = 0.0516
Epoch 44: loss = 0.0516
Epoch 45: loss = 0.0506
Epoch 46: loss = 0.0509
Epoch 47: loss = 0.0507
Epoch 48: loss = 0.0505
Epoch 49: loss = 0.0503
Epoch 50: loss = 0.0501
Epoch 51: loss = 0.0495
Epoch 52: loss = 0.0494
Epoch 53: loss = 0.0492
Epoch 54: loss = 0.0494
Epoch 55: loss = 0.0490
Epoch 56: loss = 0.0487
Epoch 57: loss = 0.0486
Epoch 58: loss = 0.0482
Epoch 59: loss = 0.0485
Epoch 60: loss = 0.0481
Epoch 61: loss = 0.0477
Epoch 62: loss = 0.0479
Epoch 63: loss = 0.0475
Epoch 64: loss = 0.0474
Epoch 65: loss = 0.0469
Epoch 66: loss = 0.0469
Epoch 67: loss = 0.0469
Epoch 68: loss = 0.0465
Epoch 69: loss = 0.0463
Epoch 70: loss = 0.0464
Epoch 71: loss = 0.0459
Epoch 72: loss = 0.0457
Epoch 73: loss = 0.0455
Epoch 74: loss = 0.0457
Epoch 75: loss = 0.0456
Epoch 76: loss = 0.0457
Epoch 77: loss = 0.0454
Epoch 78: loss = 0.0450
Epoch 79: loss = 0.0448
Epoch 80: loss = 0.0450
Epoch 81: loss = 0.0447
Epoch 82: loss = 0.0451
Epoch 83: loss = 0.0449
Epoch 84: loss = 0.0443
Epoch 85: loss = 0.0446
Epoch 86: loss = 0.0445
Epoch 87: loss = 0.0442
Epoch 88: loss = 0.0438
Epoch 89: loss = 0.0441
Epoch 90: loss = 0.0438
Epoch 91: loss = 0.0439
Epoch 92: loss = 0.0438
Epoch 93: loss = 0.0437
Epoch 94: loss = 0.0437
Epoch 95: loss = 0.0432
Epoch 96: loss = 0.0429
Epoch 97: loss = 0.0431
Epoch 98: loss = 0.0430
Epoch 99: loss = 0.0431
Max f1 score of predicting reference edges: 0.9398 (precision = 0.9482, recall = 0.9317), threshold = -0.0458
Max f1 score of predicting citation edges: 0.9045 (precision = 0.8878, recall = 0.9218)
Max f1 score of predicting coauthor edges: 0.9826 (precision = 0.9736, recall = 0.9917)
